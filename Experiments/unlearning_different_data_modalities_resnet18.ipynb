{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5cc4b572",
   "metadata": {},
   "source": [
    "# Experiment: Unlearning Different Data Modalities and Predictive Uncertainty (ResNet-18)\n",
    "\n",
    "We will compare how unlearning the same proportion (5%) of three different data modalities affects predictive uncertainty (ECE and Brier Score):\n",
    "\n",
    "- Random instances (5% random training samples)\n",
    "- Gaussian-noise instances (5% of samples with added Gaussian noise)\n",
    "- Modified-label instances (5% of samples with randomly flipped labels)\n",
    "\n",
    "Dataset/model: CIFAR-10 with ResNet-18\n",
    "Unlearning method: First-order based (single-step gradient removal)\n",
    "Uncertainty method: Temperature scaling (evaluate ECE and Brier Score)\n",
    "\n",
    "Runs: 3 repeats per modality. The notebook will produce a results table with mean ± std for ECE and BS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1efc97a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "import numpy as np\n",
    "import random\n",
    "import copy\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch.utils.data import DataLoader, Subset, Dataset\n",
    "from torch import optim\n",
    "from torchvision import transforms, datasets, models\n",
    "from scipy.special import softmax\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    cudnn.benchmark = True\n",
    "    device = \"cuda:0\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "print('Device:', device)\n",
    "\n",
    "def set_random_seed(seed=42):\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "\n",
    "set_random_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5298596f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 50000, Calib: 5000, Test: 5000\n"
     ]
    }
   ],
   "source": [
    "data_mean = (0.4914, 0.4822, 0.4465)\n",
    "data_std = (0.2023, 0.1994, 0.2010)\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(data_mean, data_std),\n",
    "])\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(data_mean, data_std),\n",
    "])\n",
    "\n",
    "train_data = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
    "test_set = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
    "\n",
    "cali_indices, test_indices = train_test_split(range(len(test_set)), test_size=0.5, stratify=test_set.targets)\n",
    "cali_data = Subset(test_set, cali_indices)\n",
    "test_data = Subset(test_set, test_indices)\n",
    "\n",
    "batch_size = 128\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "cali_loader = DataLoader(cali_data, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print(f'Train: {len(train_data)}, Calib: {len(cali_data)}, Test: {len(test_data)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa83e705",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ResNet-18 for CIFAR-10\n",
    "class ResNet18CIFAR(nn.Module):\n",
    "    def __init__(self, num_classes=10, dropout_rate=0.5):\n",
    "        super(ResNet18CIFAR, self).__init__()\n",
    "        self.resnet = models.resnet18(pretrained=False)\n",
    "        self.resnet.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.resnet.maxpool = nn.Identity()\n",
    "        self.resnet.fc = nn.Linear(512, num_classes)\n",
    "        self.dropout = nn.Dropout(p=dropout_rate)\n",
    "        \n",
    "    def forward(self, x, dropout=False):\n",
    "        x = self.resnet.conv1(x)\n",
    "        x = self.resnet.bn1(x)\n",
    "        x = self.resnet.relu(x)\n",
    "        x = self.resnet.maxpool(x)\n",
    "        x = self.resnet.layer1(x)\n",
    "        x = self.resnet.layer2(x)\n",
    "        x = self.resnet.layer3(x)\n",
    "        x = self.resnet.layer4(x)\n",
    "        x = self.resnet.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        if dropout:\n",
    "            x = self.dropout(x)\n",
    "        x = self.resnet.fc(x)\n",
    "        return x\n",
    "\n",
    "def train(model, train_loader, loss_func, optimizer, epochs=10):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        running_loss, n_batches, total, correct = 0.0, 0, 0, 0\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = loss_func(outputs, labels)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            n_batches += 1\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "        if (epoch+1) % max(1, epochs//5) == 0:\n",
    "            print(f'Epoch {epoch+1}/{epochs}, loss: {running_loss/n_batches:.4f}, acc: {100*correct/total:.2f}%')\n",
    "\n",
    "def test(model, data_loader):\n",
    "    model.eval()\n",
    "    total, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in data_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    return correct / total\n",
    "\n",
    "# ECE and BS\n",
    "def one_hot_encode(labels, num_classes=None):\n",
    "    if num_classes is None:\n",
    "        num_classes = len(np.unique(labels))\n",
    "    return np.eye(num_classes)[labels]\n",
    "\n",
    "def get_calibration_error(probs, labels, bin_upper_bounds, num_bins):\n",
    "    if np.size(probs) == 0:\n",
    "        return 0\n",
    "    bin_indices = np.digitize(probs, bin_upper_bounds)\n",
    "    sums = np.bincount(bin_indices, weights=probs, minlength=num_bins).astype(np.float64)\n",
    "    counts = np.bincount(bin_indices, minlength=num_bins) + np.finfo(sums.dtype).eps\n",
    "    confs = sums / counts\n",
    "    accs = np.bincount(bin_indices, weights=labels, minlength=num_bins) / counts\n",
    "    calibration_errors = accs - confs\n",
    "    weighting = counts / float(len(probs.flatten()))\n",
    "    weighted_calibration_error = calibration_errors * weighting\n",
    "    return np.sum(np.abs(weighted_calibration_error))\n",
    "\n",
    "def ECE(probs, labels, num_bins=10):\n",
    "    num_classes = probs.shape[1]\n",
    "    labels_matrix = one_hot_encode(labels, probs.shape[1])\n",
    "    bin_upper_bounds = np.histogram_bin_edges([], bins=num_bins, range=(0.0, 1.0))[1:]\n",
    "    labels_matrix = labels_matrix[range(len(probs)), np.argmax(probs, axis=1)]\n",
    "    probs_matrix = probs[range(len(probs)), np.argmax(probs, axis=1)]\n",
    "    calibration_error = get_calibration_error(probs_matrix.flatten(), labels_matrix.flatten(), bin_upper_bounds, num_bins)\n",
    "    return calibration_error\n",
    "\n",
    "def BS(probs, labels):\n",
    "    n_samples, n_classes = probs.shape\n",
    "    labels_matrix = one_hot_encode(labels, n_classes)\n",
    "    brier_score = np.sum((probs - labels_matrix) ** 2) / n_samples\n",
    "    return brier_score\n",
    "\n",
    "# Temperature scaling\n",
    "class TemperatureScaling():\n",
    "    def __init__(self, temp=1, maxiter=50, solver=\"BFGS\"):\n",
    "        self.temp = temp\n",
    "        self.maxiter = maxiter\n",
    "        self.solver = solver\n",
    "    def _loss_fun(self, x, probs, true):\n",
    "        scaled_probs = self.predict(probs, x)\n",
    "        loss = log_loss(y_true=true, y_pred=scaled_probs)\n",
    "        return loss\n",
    "    def fit(self, logits, true):\n",
    "        true = true.flatten()\n",
    "        opt = minimize(self._loss_fun, x0=1.0, args=(logits, true), options={'maxiter': self.maxiter}, method=self.solver)\n",
    "        self.temp = opt.x[0]\n",
    "        return opt\n",
    "    def predict(self, logits, temp=None):\n",
    "        if temp is None:\n",
    "            return softmax(logits / self.temp, axis=1)\n",
    "        else:\n",
    "            return softmax(logits / temp, axis=1)\n",
    "\n",
    "def get_outputs(model, data_loader, dropout=False):\n",
    "    model.eval()\n",
    "    all_labels, all_logits = [], []\n",
    "    with torch.no_grad():\n",
    "        for images, labels in data_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images, dropout=dropout)\n",
    "            all_labels.append(labels.detach().cpu().numpy())\n",
    "            all_logits.append(outputs.detach().cpu().numpy())\n",
    "    all_labels = np.concatenate(all_labels, axis=0)\n",
    "    all_logits = np.concatenate(all_logits, axis=0)\n",
    "    return all_labels, all_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "616f9362",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First-order unlearning\n",
    "def get_grad_diff(model, unlearn_loader):\n",
    "    loss_func = nn.CrossEntropyLoss(reduction=\"sum\")\n",
    "    model.train()\n",
    "    grads = []\n",
    "    for i, (images, labels) in enumerate(unlearn_loader):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        result_z = model(images)\n",
    "        loss_z = loss_func(result_z, labels)\n",
    "        loss_diff = -loss_z\n",
    "        differentiable_params = [p for p in model.parameters() if p.requires_grad]\n",
    "        gradients = torch.autograd.grad(loss_diff, differentiable_params, retain_graph=False)\n",
    "        grads.append(gradients)\n",
    "    grads = list(zip(*grads))\n",
    "    for i in range(len(grads)):\n",
    "        tmp = grads[i][0]\n",
    "        for j in range(1, len(grads[i])):\n",
    "            tmp = torch.add(tmp, grads[i][j])\n",
    "        grads[i] = tmp\n",
    "    return grads\n",
    "\n",
    "def first_order_unlearn(model, unlearn_loader, tau=2e-5):\n",
    "    net_unlearn = copy.deepcopy(model)\n",
    "    diff = get_grad_diff(net_unlearn, unlearn_loader)\n",
    "    d_theta = diff\n",
    "    net_unlearn.eval()\n",
    "    with torch.no_grad():\n",
    "        for p in net_unlearn.parameters():\n",
    "            if p.requires_grad:\n",
    "                new_p = p - tau * d_theta.pop(0)\n",
    "                p.copy_(new_p)\n",
    "    return net_unlearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c9c19e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready — use run_modality_experiment() to run the full experiments.\n"
     ]
    }
   ],
   "source": [
    "# Modality generators\n",
    "class NoisyDataset(Dataset):\n",
    "    \"\"\"Wraps a dataset and applies Gaussian noise to specified indices.\"\"\"\n",
    "    def __init__(self, base_dataset, noise_indices=set(), sigma=0.1):\n",
    "        self.base = base_dataset\n",
    "        self.noise_indices = set(noise_indices)\n",
    "        self.sigma = sigma\n",
    "    def __len__(self):\n",
    "        return len(self.base)\n",
    "    def __getitem__(self, idx):\n",
    "        x, y = self.base[idx]\n",
    "        if idx in self.noise_indices:\n",
    "            noise = torch.randn_like(x) * self.sigma\n",
    "            x = x + noise\n",
    "            x = torch.clamp(x, -3.0, 3.0)\n",
    "        return x, y\n",
    "\n",
    "class LabelFlippedDataset(Dataset):\n",
    "    \"\"\"Wraps a dataset and flips labels for specified indices to random labels.\"\"\"\n",
    "    def __init__(self, base_dataset, flip_indices=set(), num_classes=10):\n",
    "        self.base = base_dataset\n",
    "        self.flip_indices = set(flip_indices)\n",
    "        self.num_classes = num_classes\n",
    "    def __len__(self):\n",
    "        return len(self.base)\n",
    "    def __getitem__(self, idx):\n",
    "        x, y = self.base[idx]\n",
    "        if idx in self.flip_indices:\n",
    "            new_y = int(random.choice([c for c in range(self.num_classes) if c != y]))\n",
    "            return x, new_y\n",
    "        return x, y\n",
    "\n",
    "def run_modality_experiment(remove_prop=0.05, modality='random', num_runs=3, epochs=3, lr=0.01, tau=2e-5):\n",
    "    \"\"\"\n",
    "    modality: 'random', 'noise', or 'label'\n",
    "    Returns: dict with lists of ECE and BS (temperature-scaled) for each run\n",
    "    \"\"\"\n",
    "    ece_list = []\n",
    "    bs_list = []\n",
    "\n",
    "    num_samples = len(train_data)\n",
    "    remove_count = int(num_samples * remove_prop)\n",
    "\n",
    "    for run in range(num_runs):\n",
    "        print(f\"Run {run+1}/{num_runs} — modality: {modality} — removing {remove_count} samples\")\n",
    "        set_random_seed(100 + run)\n",
    "\n",
    "        # Train base model on full training set\n",
    "        model = ResNet18CIFAR().to(device)\n",
    "        loss_func = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9, weight_decay=5e-4)\n",
    "        train(model, train_loader, loss_func, optimizer, epochs=epochs)\n",
    "\n",
    "        # Prepare indices to remove based on modality\n",
    "        if modality == 'random':\n",
    "            remove_indices = set(random.sample(range(num_samples), remove_count))\n",
    "            train_mod = train_data\n",
    "        elif modality == 'noise':\n",
    "            noisy_indices = set(random.sample(range(num_samples), int(num_samples * 0.2)))\n",
    "            remove_indices = set(random.sample(list(noisy_indices), remove_count))\n",
    "            train_mod = NoisyDataset(train_data, noise_indices=noisy_indices, sigma=0.2)\n",
    "        elif modality == 'label':\n",
    "            flipped_indices = set(random.sample(range(num_samples), int(num_samples * 0.2)))\n",
    "            remove_indices = set(random.sample(list(flipped_indices), remove_count))\n",
    "            train_mod = LabelFlippedDataset(train_data, flip_indices=flipped_indices, num_classes=10)\n",
    "        else:\n",
    "            raise ValueError('Unknown modality')\n",
    "\n",
    "        # Create DataLoader for unlearn indices\n",
    "        unlearn_subset = Subset(train_mod, list(remove_indices))\n",
    "        retain_indices = [i for i in range(num_samples) if i not in remove_indices]\n",
    "        retain_subset = Subset(train_mod, retain_indices)\n",
    "\n",
    "        unlearn_loader = DataLoader(unlearn_subset, batch_size=128, shuffle=False)\n",
    "        retain_loader = DataLoader(retain_subset, batch_size=128, shuffle=True)\n",
    "\n",
    "        # Apply first-order unlearning\n",
    "        model_unlearned = first_order_unlearn(model, unlearn_loader, tau=tau)\n",
    "\n",
    "        # Evaluate using temperature scaling\n",
    "        cali_labels, cali_logits = get_outputs(model_unlearned, cali_loader, dropout=False)\n",
    "        test_labels, test_logits = get_outputs(model_unlearned, test_loader, dropout=False)\n",
    "\n",
    "        ts = TemperatureScaling()\n",
    "        try:\n",
    "            ts.fit(cali_logits, cali_labels)\n",
    "        except Exception as e:\n",
    "            print('Temperature scaling fit failed:', e)\n",
    "        test_probs_ts = ts.predict(test_logits)\n",
    "\n",
    "        ece_val = ECE(test_probs_ts, test_labels)\n",
    "        bs_val = BS(test_probs_ts, test_labels)\n",
    "\n",
    "        print(f'  Run result — ECE: {ece_val:.4f}, BS: {bs_val:.4f}')\n",
    "\n",
    "        ece_list.append(ece_val)\n",
    "        bs_list.append(bs_val)\n",
    "\n",
    "    return {'ECE': ece_list, 'BS': bs_list}\n",
    "\n",
    "smoke_params = {'remove_prop': 0.05, 'num_runs': 1, 'epochs': 1}\n",
    "print('Finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244f9088",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Running modality: random\n",
      "================================================================================\n",
      "Run 1/3 — modality: random — removing 2500 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/raghavkaashyap/Desktop/ISU/Research/ISU-Undergraduate-Research-F25/.venv/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/raghavkaashyap/Desktop/ISU/Research/ISU-Undergraduate-Research-F25/.venv/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8, loss: 1.4203, acc: 47.76%\n",
      "Epoch 2/8, loss: 0.9031, acc: 68.03%\n",
      "Epoch 3/8, loss: 0.6437, acc: 77.45%\n",
      "Epoch 4/8, loss: 0.4496, acc: 84.40%\n",
      "Epoch 5/8, loss: 0.2906, acc: 90.02%\n",
      "Epoch 6/8, loss: 0.1822, acc: 93.81%\n",
      "Epoch 7/8, loss: 0.1315, acc: 95.42%\n",
      "Epoch 8/8, loss: 0.0813, acc: 97.32%\n",
      "  Run result — ECE: 0.0169, BS: 0.3552\n",
      "Run 2/3 — modality: random — removing 2500 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/raghavkaashyap/Desktop/ISU/Research/ISU-Undergraduate-Research-F25/.venv/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/raghavkaashyap/Desktop/ISU/Research/ISU-Undergraduate-Research-F25/.venv/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8, loss: 1.4228, acc: 47.59%\n",
      "Epoch 2/8, loss: 0.8931, acc: 68.20%\n",
      "Epoch 3/8, loss: 0.6374, acc: 77.65%\n",
      "Epoch 4/8, loss: 0.4443, acc: 84.58%\n",
      "Epoch 5/8, loss: 0.2870, acc: 90.12%\n",
      "Epoch 6/8, loss: 0.1830, acc: 93.65%\n",
      "Epoch 7/8, loss: 0.1239, acc: 95.72%\n",
      "Epoch 8/8, loss: 0.0818, acc: 97.29%\n",
      "  Run result — ECE: 0.0133, BS: 0.3470\n",
      "Run 3/3 — modality: random — removing 2500 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/raghavkaashyap/Desktop/ISU/Research/ISU-Undergraduate-Research-F25/.venv/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/raghavkaashyap/Desktop/ISU/Research/ISU-Undergraduate-Research-F25/.venv/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8, loss: 1.4158, acc: 48.38%\n",
      "Epoch 2/8, loss: 0.9188, acc: 67.18%\n",
      "Epoch 3/8, loss: 0.6515, acc: 77.12%\n",
      "Epoch 4/8, loss: 0.4639, acc: 83.73%\n",
      "Epoch 5/8, loss: 0.3003, acc: 89.56%\n",
      "Epoch 6/8, loss: 0.1938, acc: 93.26%\n",
      "Epoch 7/8, loss: 0.1268, acc: 95.68%\n",
      "Epoch 8/8, loss: 0.0964, acc: 96.71%\n",
      "  Run result — ECE: 0.0108, BS: 0.3144\n",
      "\n",
      "================================================================================\n",
      "Running modality: noise\n",
      "================================================================================\n",
      "Run 1/3 — modality: noise — removing 2500 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/raghavkaashyap/Desktop/ISU/Research/ISU-Undergraduate-Research-F25/.venv/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/raghavkaashyap/Desktop/ISU/Research/ISU-Undergraduate-Research-F25/.venv/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8, loss: 1.4203, acc: 47.76%\n",
      "Epoch 2/8, loss: 0.9031, acc: 68.03%\n",
      "Epoch 3/8, loss: 0.6437, acc: 77.45%\n",
      "Epoch 4/8, loss: 0.4496, acc: 84.40%\n",
      "Epoch 5/8, loss: 0.2906, acc: 90.02%\n",
      "Epoch 6/8, loss: 0.1822, acc: 93.81%\n",
      "Epoch 7/8, loss: 0.1315, acc: 95.42%\n",
      "Epoch 8/8, loss: 0.0813, acc: 97.32%\n",
      "  Run result — ECE: 0.0144, BS: 0.3812\n",
      "Run 2/3 — modality: noise — removing 2500 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/raghavkaashyap/Desktop/ISU/Research/ISU-Undergraduate-Research-F25/.venv/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/raghavkaashyap/Desktop/ISU/Research/ISU-Undergraduate-Research-F25/.venv/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8, loss: 1.4228, acc: 47.59%\n",
      "Epoch 2/8, loss: 0.8931, acc: 68.20%\n",
      "Epoch 3/8, loss: 0.6374, acc: 77.65%\n",
      "Epoch 4/8, loss: 0.4443, acc: 84.58%\n",
      "Epoch 5/8, loss: 0.2870, acc: 90.12%\n",
      "Epoch 6/8, loss: 0.1830, acc: 93.65%\n",
      "Epoch 7/8, loss: 0.1239, acc: 95.72%\n",
      "Epoch 8/8, loss: 0.0818, acc: 97.29%\n",
      "  Run result — ECE: 0.0160, BS: 0.3739\n",
      "Run 3/3 — modality: noise — removing 2500 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/raghavkaashyap/Desktop/ISU/Research/ISU-Undergraduate-Research-F25/.venv/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/raghavkaashyap/Desktop/ISU/Research/ISU-Undergraduate-Research-F25/.venv/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8, loss: 1.4158, acc: 48.38%\n",
      "Epoch 2/8, loss: 0.9188, acc: 67.18%\n",
      "Epoch 3/8, loss: 0.6515, acc: 77.12%\n",
      "Epoch 4/8, loss: 0.4639, acc: 83.73%\n",
      "Epoch 5/8, loss: 0.3003, acc: 89.56%\n",
      "Epoch 6/8, loss: 0.1938, acc: 93.26%\n",
      "Epoch 7/8, loss: 0.1268, acc: 95.68%\n",
      "Epoch 8/8, loss: 0.0964, acc: 96.71%\n",
      "  Run result — ECE: 0.0097, BS: 0.3239\n",
      "\n",
      "================================================================================\n",
      "Running modality: label\n",
      "================================================================================\n",
      "Run 1/3 — modality: label — removing 2500 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/raghavkaashyap/Desktop/ISU/Research/ISU-Undergraduate-Research-F25/.venv/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/raghavkaashyap/Desktop/ISU/Research/ISU-Undergraduate-Research-F25/.venv/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8, loss: 1.4203, acc: 47.76%\n",
      "Epoch 2/8, loss: 0.9031, acc: 68.03%\n"
     ]
    }
   ],
   "source": [
    "modalities = ['random', 'noise', 'label']\n",
    "all_stats = {}\n",
    "\n",
    "for mod in modalities:\n",
    "    print('\\n' + '='*80)\n",
    "    print(f'Running modality: {mod}')\n",
    "    print('='*80)\n",
    "    res = run_modality_experiment(remove_prop=0.05, modality=mod, num_runs=3, epochs=3, lr=0.01, tau=2e-5)\n",
    "\n",
    "    ece_vals = np.array(res['ECE'])\n",
    "    bs_vals = np.array(res['BS'])\n",
    "\n",
    "    ece_mean = ece_vals.mean()\n",
    "    ece_std = ece_vals.std()\n",
    "    bs_mean = bs_vals.mean()\n",
    "    bs_std = bs_vals.std()\n",
    "\n",
    "    all_stats[mod] = {\n",
    "        'ECE_vals': ece_vals.tolist(),\n",
    "        'BS_vals': bs_vals.tolist(),\n",
    "        'ECE_mean': float(ece_mean),\n",
    "        'ECE_std': float(ece_std),\n",
    "        'BS_mean': float(bs_mean),\n",
    "        'BS_std': float(bs_std)\n",
    "    }\n",
    "\n",
    "print('\\nRESULTS SUMMARY (mean ± std) — remove 5% per modality')\n",
    "print(f\"{'Modality':<12} {'ECE (mean±std)':<25} {'BS (mean±std)':<25}\")\n",
    "print('-'*70)\n",
    "for mod in modalities:\n",
    "    e_me, e_st = all_stats[mod]['ECE_mean'], all_stats[mod]['ECE_std']\n",
    "    b_me, b_st = all_stats[mod]['BS_mean'], all_stats[mod]['BS_std']\n",
    "    print(f\"{mod:<12} {e_me:7.4f} ± {e_st:<7.4f}    {b_me:7.4f} ± {b_st:<7.4f}\")\n",
    "\n",
    "all_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41c42d45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No results available in `all_stats`. Run the experiment cell first to populate results.\n"
     ]
    }
   ],
   "source": [
    "# Display names mapped to experiment keys\n",
    "modalities_map = [\n",
    "    ('Instances', 'random'),\n",
    "    ('Gaussian Noises', 'noise'),\n",
    "    ('Modified Labels', 'label'),\n",
    "]\n",
    "\n",
    "if 'all_stats' not in globals():\n",
    "    print(\"No results available in `all_stats`. Run the experiment cell first to populate results.\")\n",
    "else:\n",
    "    print('\\nRESULTS SUMMARY (remove 5% per modality) — ResNet-18')\n",
    "    print(f\"{'Modality':<20} {'ECE (mean ± std)':<30} {'BS (mean ± std)':<30}\")\n",
    "    print('-' * 80)\n",
    "    for display_name, key in modalities_map:\n",
    "        # Look up by canonical key (used when experiments were run), fallback to display name\n",
    "        s = all_stats.get(key, all_stats.get(display_name))\n",
    "        if s is None:\n",
    "            print(f\"{display_name:<20} {'N/A':<30} {'N/A':<30}\")\n",
    "            continue\n",
    "        if 'ECE_mean' in s and 'ECE_std' in s:\n",
    "            e_me, e_st = s['ECE_mean'], s['ECE_std']\n",
    "        elif 'ECE' in s and isinstance(s['ECE'], dict):\n",
    "            e_me, e_st = s['ECE']['mean'], s['ECE']['std']\n",
    "        else:\n",
    "            e_vals = np.array(s.get('ECE_vals', s.get('ECE', [])))\n",
    "            e_me, e_st = (float(np.mean(e_vals)), float(np.std(e_vals))) if len(e_vals)>0 else (None, None)\n",
    "\n",
    "        if 'BS_mean' in s and 'BS_std' in s:\n",
    "            b_me, b_st = s['BS_mean'], s['BS_std']\n",
    "        elif 'BS' in s and isinstance(s['BS'], dict):\n",
    "            b_me, b_st = s['BS']['mean'], s['BS']['std']\n",
    "        else:\n",
    "            b_vals = np.array(s.get('BS_vals', s.get('BS', [])))\n",
    "            b_me, b_st = (float(np.mean(b_vals)), float(np.std(b_vals))) if len(b_vals)>0 else (None, None)\n",
    "\n",
    "        if None in (e_me, e_st, b_me, b_st):\n",
    "            print(f\"{display_name:<20} {'N/A':<30} {'N/A':<30}\")\n",
    "        else:\n",
    "            print(f\"{display_name:<20} {e_me:7.4f} ± {e_st:<7.4f}    {b_me:7.4f} ± {b_st:<7.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.9.6)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
